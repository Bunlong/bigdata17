# Introduction {#intro}

## Prerequisites

For BST262 (Computing for Big Data), we assume familiarity with the material covered in BST260 (Introductio to Data Science).

We will use R to present concepts that are mostly language-agnostic.  We could have used Python, as in BST261 (Data Science II).

## Syllabus

Week 1 - Basic tools

- Lecture 1. Unix scripting, make
- Lecture 2. Version control: Git and GitHub (guest lecture: Ista Zhan)

Week 2 - Creating and maintaining R packages

- Lecture 3. Rationale, package structure, available tools
- Lecture 4. Basics of software engineering: unit testing, continuous integration, code coverage

Week 3 - Software optimization

- Lecture 5. Measuring performance: profiling and benchmarking tools
- Lecture 6. Improving performance: an introduction to C/C++, Rcpp

Week 4 – Databases

- Lecture 7. Overview of SQL (SQLite, PostgreSQL) and noSQL databases (HBase,
MongoDB, Cassandra, BigTable, ...)
- Lecture 8. R database interfaces (in particular through dplyr)

Week 5 - Analyzing data that does not fit in memory

- Lecture 9. Pure R solutions (sampling, ff and ffbase, other interpreters). JVM solutions (h20, Spark)
- Lecture 10. An introduction to parallel computing; clusters and cloud computing.
“Divide and Conquer” (MapReduce approaches)

Week 6 – Visualization

- Lecture 11. Principles of visualization (guest lecture: James Honaker)
- Lecture 12. Maps and GIS: principles of GIS, using R as a GIS, PostGIS

Weeks 7 & 8 - Guest lectures (order and precise schedule TBD)

- Software project management (Danny Brooke)
- R and Spark (Ellen Kraffmiller and Robert Treacy) Advanced GIS and remote sensing (TBD)
- Cluster architecture (William J. Horka)

## Evaluation

Grades will be based on two mandatory problem sets. Each problem set will correspond to 50% (= 50 points) of the final grade. The first problem set will be available by the end of week 3 and the second problem set by the end of week 6.

You will be required to submit problem set solutions within two weeks. Grades, and feedback when appropriate, will be returned two weeks after submission.

You will submit a markdown document that combines commented code for data analysis and detailed and structured explanations of the algorithms and software tools that you used.

## Software packages

We will mostly use R in this course.  Some examples will be run in Python.  In general, we will use free and open-source software programs such as PostgreSQL or Spark.

## Datasets

### MovieLens

MovieLens by @Harper2015 [, https://grouplens.org/datasets/movielens/] collects datasets from the website https://movielens.org/.

There are datasets of different sizes, notably:

1. Small (1MB)
2. Benchmark (~190MB zipped)

```{r}
ratings <- read.csv("data17/ml-latest-small/ratings.csv")
head(ratings)
```
```{r}
links <- read.csv("data17/ml-latest-small/links.csv")
head(links)
```

```{r}
movies <- read.csv("data17/ml-latest-small/movies.csv")
head(movies)
```
```{r}
tags <- read.csv("data17/ml-latest-small/tags.csv")
head(tags)
```

### Airlines data

```{r}
# https://github.com/h2oai/h2o-2/wiki/Hacking-Airline-DataSet-with-H2O
```


### Census

### Health claims

Synthetica Medicare data

```{r}
# https://www.cms.gov/Research-Statistics-Data-and-Systems/Downloadable-Public-Use-Files/SynPUFs/DE_Syn_PUF.html
# Sample 1
# https://www.cms.gov/Research-Statistics-Data-and-Systems/Downloadable-Public-Use-Files/SynPUFs/DESample01.html
```


### GIS: PM~2.5~ exposure
PM~2.5~ exposure

### Methylation?

### GWAS

